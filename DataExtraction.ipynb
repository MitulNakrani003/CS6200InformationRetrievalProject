{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "from tqdm.notebook import tqdm\n",
    "import wikipedia\n",
    "from wikipedia.exceptions import WikipediaException, DisambiguationError, PageError\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Working directory set to: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject\n"
     ]
    }
   ],
   "source": [
    "print(\"✅ Working directory set to:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/DataExtraction.ipynb\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/requirements.txt\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/SampleDataAndGradeContract.txt\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/README.md\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/ORIG_HEAD\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/config\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/HEAD\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/description\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/index\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/packed-refs\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/COMMIT_EDITMSG\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/FETCH_HEAD\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/objects/61/3bad00d3e90f3a8c4cbbfc1f63d2ab2ea02b7a\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/objects/59/7067a928fc7f9462e4cc5fe468aff8f21b13df\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/objects/59/4bf3aac127f4c4a7871a3d996561371ba1d4c1\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/objects/3e/614e8bbb8eeadeb56823aabc4e0f4c5044d84e\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/objects/50/f48f7c91b7071522488bc66d1ee03ac10bb5fb\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/objects/56/9bb14f4fee07da53aeb72e5c9488e0dcb058af\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/objects/94/5cf7b4ddd2f9c38ed58f098c3610a3fa70d9f0\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/objects/5f/67b084dea64f05f6bc72317d84b5c5a12c829b\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/objects/33/f921086ad383fde9c2a68b2b9b97e48f6950b1\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/objects/05/cd899ef3a9682fac04171b9b877cddcda121c5\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/objects/02/4d4a40b9970fb29407b6ad84f5f44a455f44cb\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/objects/a3/e6e06d1aedaac7598f9dc24da8e9a0c81ce2ca\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/objects/a2/c7ed3f6acd219f08f4ef01acb71edd9bc56369\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/objects/bd/e71b9ce2a9ec7a61edeef96cafc19de5754e42\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/objects/d8/d5745c5669f93556679fcdca2c502f38ce7aa4\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/objects/f4/88d07081cc4d20c235f3cd944df0d905e0b2ca\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/objects/f3/c7e750910a2b333f394c1be5d4d81afe423f9e\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/objects/c7/664b7f695487101dd649d851106f6ff3fa129a\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/objects/e3/fdeb6fb894d5c3ac5b728cb179604df3ce7ce2\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/objects/4e/8c8facc51dac02bf59c50a0df8a84b8bc7d1e5\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/objects/pack/pack-b897107111719c3b807760ddbd3c30b087c2ee2e.pack\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/objects/pack/pack-b897107111719c3b807760ddbd3c30b087c2ee2e.idx\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/objects/29/83c641ae0d4ea4c6974f668480ccac25a43949\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/objects/45/768569b10e3f461a204f0201d2b8da55155c2a\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/objects/87/7e4de77d58f35c7c8d2e83099c9593f34be0c7\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/objects/87/24c72ce240f63dcebc78f563a38f85c718a3e6\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/objects/80/dc7f2d852c9f1c9df3a1de0fc3c1587581414e\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/objects/7b/1fc2f48333f005e212eeb87d1c76a4ced7a34c\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/objects/8f/9690a00b663c2d057ef79e0284af1b0260d8d0\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/objects/8a/a27619607c71bf3c321b76319ed51e9158c9b7\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/objects/2f/b08546d7c2ba3135d58de0922e8fc95a22331a\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/objects/9f/f068ce284253b975a390f607df646ad7072ac3\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/objects/96/e0e97e564af087dbbb92afce43cbc0982e4de7\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/objects/3f/662dc07b85bde71c52f7e87c5a295d8bb9be7b\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/objects/5e/63ef26dcb2c20ba5a73030207a6308f9c143d2\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/objects/63/d268f0c1025ae8cf2ae62e183992be67f749e3\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/objects/64/c4af3c785c7a779a91de06990163a965f5e730\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/objects/64/ffc844270d78c29f9b44bd613025129e7ea9d1\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/objects/90/bc9096ec372daaafe61ad273503ed8bd03bbd6\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/objects/ba/c275ac2f427ad235f6736e2ed7ca9e2d134e10\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/objects/2d/19912078ea4a86dbb114875705b7b9c654c14c\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/objects/83/b6673ff5c1ee659f6b2f7739b81f07290d9b7d\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/objects/15/4c2c3564d0f1153894d5960137742e71fbde81\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/objects/15/6a1967ddb212c3ae3fa14b556984e40b2efda2\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/objects/85/3de04d57e661e7a5e47ff06a42864078912729\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/objects/1c/d279eb1e0f5f2de1e562494cb3c5457b3afc16\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/objects/49/c9a1ae7444249bf67075ba314cb35257046d22\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/objects/2e/890d41720d9439dbe70c0aadb7b963dada2bd6\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/objects/8b/ae23741a3aa0a127c691146906a13b62d8487f\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/objects/13/3413bc2f7df26c922b3fe489aa72287f514e4a\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/info/exclude\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/logs/HEAD\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/logs/refs/stash\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/logs/refs/heads/master\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/logs/refs/remotes/origin/HEAD\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/logs/refs/remotes/origin/master\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/hooks/commit-msg.sample\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/hooks/pre-rebase.sample\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/hooks/pre-commit.sample\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/hooks/applypatch-msg.sample\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/hooks/fsmonitor-watchman.sample\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/hooks/pre-receive.sample\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/hooks/prepare-commit-msg.sample\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/hooks/post-update.sample\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/hooks/pre-merge-commit.sample\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/hooks/pre-applypatch.sample\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/hooks/pre-push.sample\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/hooks/update.sample\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/hooks/push-to-checkout.sample\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/refs/stash\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/refs/heads/master\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/refs/remotes/origin/HEAD\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/.git/refs/remotes/origin/master\n",
      "Found: /Users/shailshah/Desktop/NEU MSCS/Sem4/IR/Final Project/CS6200InformationRetrievalProject/data/ManualAnnotatedQueries.json\n"
     ]
    }
   ],
   "source": [
    "for root, dirs, files in os.walk(os.getcwd()):\n",
    "    for file in files:\n",
    "        print(\"Found:\", os.path.join(root, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/shailshah/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/shailshah/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/shailshah/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ssl\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "# Now download NLTK data\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the annotated queries data from JSON file\n",
    "def load_queries(json_path):\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data['queries']\n",
    "\n",
    "# Function to extract page title from Wikipedia URL\n",
    "def extract_title_from_url(url):\n",
    "    # Extract the page title from the URL path\n",
    "    parts = url.split('/')\n",
    "    title = parts[-1]\n",
    "    # Replace underscores with spaces and URL decode\n",
    "    title = title.replace('_', ' ')\n",
    "    return title\n",
    "\n",
    "# Function to extract content from Wikipedia using the wikipedia library\n",
    "def extract_wikipedia_content(url):\n",
    "    try:\n",
    "        # Extract the title from the URL\n",
    "        title = extract_title_from_url(url)\n",
    "        \n",
    "        # Add a small delay to be respectful\n",
    "        time.sleep(0.5)\n",
    "        \n",
    "        # Get the page content\n",
    "        page = wikipedia.page(title, auto_suggest=False)\n",
    "        content = page.content\n",
    "        \n",
    "        # Clean the content\n",
    "        content = re.sub(r'\\n+', ' ', content)  # Replace newlines with spaces\n",
    "        content = re.sub(r'\\s+', ' ', content)  # Normalize whitespace\n",
    "        content = content.strip()\n",
    "        \n",
    "        return content, page.url\n",
    "    except DisambiguationError as e:\n",
    "        print(f\"Disambiguation error for {title}: {e}\")\n",
    "        return \"\", url\n",
    "    except PageError as e:\n",
    "        print(f\"Page not found for {title}: {e}\")\n",
    "        return \"\", url\n",
    "    except WikipediaException as e:\n",
    "        print(f\"Wikipedia API error for {title}: {e}\")\n",
    "        return \"\", url\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting content for {title}: {str(e)}\")\n",
    "        return \"\", url\n",
    "\n",
    "\n",
    "# Function to preprocess text (tokenize, lemmatize, remove stopwords)\n",
    "def preprocess_text(text):\n",
    "    # Remove URLs, hyphens, and non-alphanumeric characters (except whitespace)\n",
    "    finaltext = re.sub(r'http\\S+', '', text)  # URLs\n",
    "    finaltext = re.sub(r'-', ' ', finaltext)       # Hyphens → spaces\n",
    "    finaltext = re.sub(r'[^\\w\\s]', ' ', finaltext) # Punctuation\n",
    "    \n",
    "    # Remove numbers and extra whitespace\n",
    "    finaltext = re.sub(r'\\d+', ' ', finaltext)     # Numbers\n",
    "    finaltext = re.sub(r'\\s+', ' ', finaltext).strip().lower()\n",
    "    \n",
    "    # Tokenize and lowercase\n",
    "    tokens = word_tokenize(finaltext.lower())\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # Remove non-alphabetic tokens\n",
    "    filtered_tokens = [token for token in filtered_tokens if token.isalpha()]\n",
    "    \n",
    "    # Lemmatize\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]\n",
    "    \n",
    "    # Join tokens back into a string\n",
    "    return ' '.join(lemmatized_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 50 queries from data/ManualAnnotatedQueries.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page not found for Cold storage (cryptocurrency): Page id \"Cold storage (cryptocurrency)\" does not match any pages. Try another id!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page not found for Risk and return: Page id \"Risk and return\" does not match any pages. Try another id!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page not found for Apportionment in the United States House of Representatives: Page id \"Apportionment in the United States House of Representatives\" does not match any pages. Try another id!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page not found for Meditation and education: Page id \"Meditation and education\" does not match any pages. Try another id!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page not found for Neuroscience of meditation: Page id \"Neuroscience of meditation\" does not match any pages. Try another id!\n",
      "Page not found for Meditation and neuroplasticity: Page id \"Meditation and neuroplasticity\" does not match any pages. Try another id!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page not found for Meditation and the brain: Page id \"Meditation and the brain\" does not match any pages. Try another id!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page not found for Sleep and academic performance: Page id \"Sleep and academic performance\" does not match any pages. Try another id!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page not found for Sleep and mental health: Page id \"Sleep and mental health\" does not match any pages. Try another id!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page not found for 3D printing in medicine: Page id \"3D printing in medicine\" does not match any pages. Try another id!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page not found for 3D printing in aerospace: Page id \"3D printing in aerospace\" does not match any pages. Try another id!\n",
      "Page not found for 3D printing in automotive: Page id \"3D printing in automotive\" does not match any pages. Try another id!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page not found for 3D printing in education: Page id \"3D printing in education\" does not match any pages. Try another id!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page not found for Future of 3D printing: Page id \"Future of 3D printing\" does not match any pages. Try another id!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|███████████████████████| 50/50 [03:03<00:00,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved to data/WikipediaRelevantDocs.json\n",
      "Total queries with relevant documents: 50\n",
      "Total documents extracted: 154\n",
      "Average documents per query: 3.08\n",
      "\n",
      "Sample Query:\n",
      "ID: 1\n",
      "Query: Cryptocurrency basics\n",
      "Narrative: The user wants to understand the fundamental concepts of cryptocurrencies, including how they work, ...\n",
      "\n",
      "Sample Document:\n",
      "Title: Cryptocurrency\n",
      "URL: https://en.wikipedia.org/wiki/Cryptocurrency\n",
      "Content (first 200 chars): cryptocurrency colloquially crypto digital currency designed work computer network reliant central authority government bank uphold maintain individual coin ownership record stored digital ledger bloc...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Function to build dataset with highly relevant documents\n",
    "def build_dataset(queries, output_path, min_relevance=3):\n",
    "    dataset = []\n",
    "    \n",
    "    # Process each query\n",
    "    for query in tqdm(queries, desc=\"Processing queries\"):\n",
    "        \n",
    "        if 'documents' not in query:\n",
    "            print(f\"Skipping query ID {query.get('id', 'unknown')}: No documents found\")\n",
    "            continue\n",
    "            \n",
    "        query_id = query.get('id')\n",
    "        query_text = query.get('query', '')\n",
    "        narrative = query.get('narrative', '')\n",
    "        \n",
    "        # Extract documents with relevance >= min_relevance\n",
    "        relevant_docs = []\n",
    "        for doc in query['documents']:\n",
    "            relevance = doc.get('relevance_score')\n",
    "            if relevance is not None and relevance >= min_relevance:\n",
    "                doc_url = doc.get('url', '')\n",
    "                doc_title = doc.get('title', '')\n",
    "                \n",
    "                if not doc_url:\n",
    "                    print(f\"Skipping document {doc_title}: No URL provided\")\n",
    "                    continue\n",
    "                \n",
    "                # Extract content from Wikipedia\n",
    "                content, actual_url = extract_wikipedia_content(doc_url)\n",
    "                \n",
    "                if content:\n",
    "                    preprocessed_content = preprocess_text(content)\n",
    "                    relevant_docs.append({\n",
    "                        'title': doc_title,\n",
    "                        'url': actual_url,\n",
    "                        'content': preprocessed_content,\n",
    "                        'relevance_score': relevance\n",
    "                    })\n",
    "        \n",
    "        # Only add the query if it has relevant documents\n",
    "        if relevant_docs:\n",
    "            dataset.append({\n",
    "                'query_id': query_id,\n",
    "                'query': query_text,\n",
    "                'narrative': narrative,\n",
    "                'documents': relevant_docs\n",
    "            })\n",
    "    \n",
    "    # Save the dataset as JSON\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump({'dataset': dataset}, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"Dataset saved to {output_path}\")\n",
    "    return dataset\n",
    "\n",
    "# Main execution\n",
    "json_path = 'data/ManualAnnotatedQueries.json'\n",
    "output_path = 'data/WikipediaRelevantDocs.json'\n",
    "\n",
    "# Load queries and build dataset\n",
    "queries = load_queries(json_path)\n",
    "print(f\"Loaded {len(queries)} queries from {json_path}\")\n",
    "\n",
    "# Build the dataset with documents that have relevance score >= 3\n",
    "dataset = build_dataset(queries, output_path, min_relevance=3)\n",
    "\n",
    "# Print some statistics\n",
    "total_docs = sum(len(item['documents']) for item in dataset)\n",
    "print(f\"Total queries with relevant documents: {len(dataset)}\")\n",
    "print(f\"Total documents extracted: {total_docs}\")\n",
    "print(f\"Average documents per query: {total_docs / len(dataset) if len(dataset) > 0 else 0:.2f}\")\n",
    "\n",
    "# Display first query and document as sample (if available)\n",
    "if dataset and dataset[0].get('documents'):\n",
    "    sample_query = dataset[0]\n",
    "    sample_doc = sample_query['documents'][0]\n",
    "    \n",
    "    print(\"\\nSample Query:\")\n",
    "    print(f\"ID: {sample_query.get('query_id')}\")\n",
    "    print(f\"Query: {sample_query.get('query')}\")\n",
    "    print(f\"Narrative: {sample_query.get('narrative', '')[:100]}...\")\n",
    "    \n",
    "    print(\"\\nSample Document:\")\n",
    "    print(f\"Title: {sample_doc.get('title')}\")\n",
    "    print(f\"URL: {sample_doc.get('url')}\")\n",
    "    print(f\"Content (first 200 chars): {sample_doc.get('content', '')[:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

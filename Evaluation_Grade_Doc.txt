Evaluation and Grade Document:

Models we will be working with:

Pegasus: https://huggingface.co/docs/transformers/en/model_doc/pegasus

Bart: https://huggingface.co/transformers/v2.11.0/model_doc/bart.html

T5: https://huggingface.co/docs/transformers/en/model_doc/t5

LongFormer: https://huggingface.co/docs/transformers/en/model_doc/longformer

 

Grade:
	
B	

Milestones:
1. Label at least 25 queries with their corresponding relevant documents. 
2. Collect and preprocess data based on these queries, setting up a data processing pipeline. 
3. Implement a transformer-based summarization model (BART) to generate document summaries. 
4. Apply BM25 as the retrieval model to retrieve documents based on the annotated queries. 
5. Evaluate retrieval performance using Mean Average Precision (MAP).

Grade:
B+	

Milestones:
1. Integrate an additional summarization model (Pegasus) to generate document summaries. 
2. Perform document retrieval using BM25 on the newly summarized dataset. 
3. Compare retrieval performance between the original system (full-text retrieval) and the summarization-enhanced system.


Grade:
A-	

Milestones:
1. Introduce a third summarization model (LongFormer) to analyze different summarization techniques. 
2. Apply document retrieval using BM25 and compare its performance against retrieval using LongFormer-generated summaries. 
3. Evaluate retrieval effectiveness by comparing BM25 with different summarization-enhanced retrieval models. 

Grade:
A	

Milestones:
1. Incorporate an additional retrieval model (T5) alongside BM25.
2. Optimize hyperparameters for T5, LongFormer, and BM25 to improve retrieval performance.
3. Conduct a comprehensive evaluation comparing all retrieval models (BART, Pegasus, T5, and LongFormer) to assess their effectiveness.
4. Deliver an in-depth analysis discussing the strengths, limitations, and ideal use cases for each retrieval approach.


